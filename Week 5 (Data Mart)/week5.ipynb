{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study #5 - Data Mart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "\n",
    "Data Mart is Danny’s latest venture and after running international operations for his online supermarket that specialises in fresh produce - Danny is asking for your support to analyse his sales performance.\n",
    "\n",
    "In June 2020 - large scale supply changes were made at Data Mart. All Data Mart products now use sustainable packaging methods in every single step from the farm all the way to the customer.\n",
    "\n",
    "Danny needs your help to quantify the impact of this change on the sales performance for Data Mart and it’s separate business areas.\n",
    "\n",
    "The key business question he wants you to help him answer are the following:\n",
    "- What was the quantifiable impact of the changes introduced in June 2020?\n",
    "- Which platform, region, segment and customer types were the most impacted by this change?\n",
    "- What can we do about future introduction of similar sustainability updates to the business to minimise impact on sales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity Relationship Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![week5.png](week5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Engine imports\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Python data analysis imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "user = os.environ.get(\"USER\")\n",
    "pw = os.environ.get(\"PASS\")\n",
    "db = os.environ.get(\"DB\")\n",
    "host = os.environ.get(\"HOST\")\n",
    "api = os.environ.get(\"API\")\n",
    "port = 5432\n",
    "schema = 'data_mart'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = f\"postgresql+psycopg2://{user}:{pw}@{host}:{port}/{db}\"\n",
    "alchemyEngine = create_engine(uri)\n",
    "conn = alchemyEngine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tables in the database are: \n",
      "- weekly_sales\n"
     ]
    }
   ],
   "source": [
    "rs = conn.execute(text(f\"SELECT table_name FROM information_schema.tables WHERE table_schema='{schema}'\"))\n",
    "tables = [table[0] for table in rs.fetchall()]\n",
    "print(f'The tables in the database are: \\n- {'\\n- '.join(tables)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch table information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Table [weekly_sales]\n",
      "Dimensions: 5 rows x 7 columns\n",
      "\n",
      "  week_date  region platform segment customer_type  transactions     sales\n",
      "0   31/8/20    ASIA   Retail      C3           New        120631   3656163\n",
      "1   31/8/20    ASIA   Retail      F1           New         31574    996575\n",
      "2   31/8/20     USA   Retail    null         Guest        529151  16509610\n",
      "3   31/8/20  EUROPE   Retail      C1           New          4517    141942\n",
      "4   31/8/20  AFRICA   Retail      C2           New         58046   1758388\n",
      "\n",
      "              Datatypes  NULL count\n",
      "week_date        object           0\n",
      "region           object           0\n",
      "platform         object           0\n",
      "segment          object           0\n",
      "customer_type    object           0\n",
      "transactions      int64           0\n",
      "sales             int64           0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for table in tables:\n",
    "    print(\"=================================\")\n",
    "    print(f'Table [{table}]')\n",
    "    df = pd.read_sql_query(f'SELECT * FROM {schema}.{table} LIMIT 5', conn.connection)\n",
    "    print(f'Dimensions: {df.shape[0]} rows x {df.shape[1]} columns\\n')\n",
    "    print(df.head())\n",
    "    info_df = pd.DataFrame.from_dict({'Datatypes':df.dtypes, 'NULL count':df.isna().sum()})\n",
    "    print()\n",
    "    print(info_df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(stmt: str):\n",
    "    \"\"\"Executes a given SQL statement and returns a Pandas DataFrame given the results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stmt: str\n",
    "        The SQL statement to be executed\n",
    "    \"\"\"\n",
    "    global conn\n",
    "    result = pd.read_sql_query(stmt, conn.connection)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following case study questions include some general data exploration analysis for the nodes and transactions before diving right into the core business questions and finishes with a challenging final request!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Data Cleaning**\n",
    "\n",
    "Q1: In a single query, perform the following operations and generate a new table in the `data_mart` schema named `clean_weekly_sales`:\n",
    "- Convert the `week_date` to a DATE format\n",
    "- Add a `week_number` as the second column for each `week_date` value, for example any value from the 1st of January to 7th of January will be 1, 8th to 14th will be 2 etc\n",
    "- Add a `month_number` with the calendar month for each `week_date` value as the 3rd column\n",
    "- Add a `calendar_year` column as the 4th column containing either 2018, 2019 or 2020 values\n",
    "- Add a new column called `age_band` after the original `segment` column using the following mapping on the number inside the segment value:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"week5a.png\"/>\n",
    "</p>\n",
    "\n",
    "- Add a new `demographic` column using the following mapping for the first letter in the `segment` values:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"week5b.png\" />\n",
    "</p>\n",
    "\n",
    "- Ensure all `null` string values with an `\"unknown\"` string value in the original segment column as well as the new `age_band` and `demographic` columns\n",
    "- Generate a new `avg_transaction` column as the `sales` value divided by `transactions` rounded to 2 decimal places for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Data Exploration**\n",
    "\n",
    "Q2: What day of the week is used for each `week_date` value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: What range of week numbers are missing from the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: How many total transactions were there for each year in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: What is the total sales for each region for each month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: What is the total count of transactions for each platform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: What is the percentage of sales for Retail vs Shopify for each month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: What is the percentage of sales by demographic for each year in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Which age_band and demographic values contribute the most to Retail sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Can we use the avg_transaction column to find the average transaction size for each year for Retail vs Shopify? If not - how would you calculate it instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Before and After Analysis**\n",
    "\n",
    "This technique is usually used when we inspect an important event and want to inspect the impact before and after a certain point in time.\n",
    "\n",
    "Taking the `week_date` value of 2020-06-15 as the baseline week where the Data Mart sustainable packaging changes came into effect.\n",
    "\n",
    "We would include all `week_date` values for 2020-06-15 as the start of the period after the change and the previous week_date values would be before\n",
    "\n",
    "Using this analysis approach - answer the following questions:\n",
    "\n",
    "Q11: What is the total sales for the 4 weeks before and after 2020-06-15? What is the growth or reduction rate in actual values and percentage of sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12: What about the entire 12 weeks before and after?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13: How do the sale metrics for these 2 periods before and after compare with the previous years in 2018 and 2019?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Bonus Question**\n",
    "\n",
    "Q14: Which areas of the business have the highest negative impact in sales metrics performance in 2020 for the 12 week before and after period?\n",
    "- region\n",
    "- platform\n",
    "- age_band\n",
    "- demographic\n",
    "- customer_type\n",
    "\n",
    "Do you have any further recommendations for Danny’s team at Data Mart or any interesting insights based off this analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "This case study actually is based off a real life change in Australia retailers where plastic bags were no longer provided for free - as you can expect, some customers would have changed their shopping behaviour because of this change!\n",
    "\n",
    "Analysis which is related to certain key events which can have a significant impact on sales or engagement metrics is always a part of the data analytics menu. Learning how to approach these types of problems is a super valuable lesson and hopefully these ideas can help you next time you’re faced with a tough problem like this in the workplace!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
